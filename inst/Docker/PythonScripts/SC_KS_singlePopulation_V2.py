import scipy.io
import matplotlib.pyplot as plt
import numpy as np
import os
import glob
import pandas as pd
import MyFunctions2 as F 
import time


"""
This script compares the single cell distributions for each feature with the a
reference distribution. The reference distribution is generated by aggregating 
all the distributions of single control cells for aech feature. The comparison 
is performed by KS statistic.


input: matrix of rab clusters. rows: rab clusters. columns: 
 cell label/Rab features/cell features

output: matrix of single cells. Rows: single cells. Columns: Rab features


"""


# Record the start time
start_time = time.perf_counter()

""" REFERENCE DISTRIBUTION FILE LOADING """

# Specify the folder containing the .mat control file
CTRL_path = 'C:/Users/E14Ge/Desktop/Rab cluster data/Feature extraction data/control'

# Find .xlsx control filee in the folder
CTRLxlsx_files = glob.glob(os.path.join(CTRL_path, '*.xlsx'))

# Load the Excel file into a DataFrame
CTRL_df = pd.read_excel(CTRLxlsx_files[0])

# convert to numpy array
ctrl = CTRL_df.to_numpy()

""" FILES LOADING OF THE CONDITION TO BE COMPARED """
 
# Specify the folder containing the .xlsx file to be compared to reference distribution
COMP_path = 'C:/Users/E14Ge/Desktop/Rab cluster data/Feature extraction data/condition'

# Find .xlsx control filee in the folder
COMPxlsx_files = glob.glob(os.path.join(COMP_path, '*.xlsx'))

# Load the Excel file into a DataFrame
COMP_df = pd.read_excel(COMPxlsx_files[0])

#convert to numpy array
comp = COMP_df.to_numpy()


""" DATA CLEANING """

print("Data cleaning")

# clean data from eventual nan and inf
# I get the input matrices of Rab clusters cleaned and in a numpy array form
ctrl = F.cleaning(ctrl)
comp = F.cleaning(comp)


""" KS MATRIX GENERATION """

Mcomp = int(max(comp[:,0])) # max label of treated cells


# Preprocess data into dictionary: label indicate cells. For each label i 
# a matrix where rows are Rab clusters and columns features is generated. This 
# allow to me to have already stored all the single cell distribution, improving 
# script running time
comp_groups = {label: comp[comp[:, 0] == label, :] for label in np.unique(comp[:, 0])}

#del comp_groups[0]

print('\n')
print("KS variability estimation")
print('\n')


KS_final = pd.DataFrame()

for n in range(1,12):# loop on the feature of interest (only Rab features)

    print('\n')
    print(n)
    
    #n=1
    # store KS values per single cell of each feature n
    KSv = []
    
    for i in range(1,Mcomp+1):# loop on the single cell to be compared with the reference distribution
    
        # Check if i exists in comp_groups
        if i not in comp_groups:
            print(f"\nWarning: Index {i} not found in comp_groups. Skipping this iteration.")
            continue
        
        # Calculate percentage of loop procedure
        percent = (i / Mcomp) * 100
        
        # Print percentage dynamically
        print(f"\rProgress: {percent:.2f}%", end="")
        
        
        # Generate the single cell distribution to be compared for feature n 
        compN = comp_groups[i][:, n]
        
        # Generate the reference distribution for feature n
        Ref = ctrl[:, n]
        
        # perform KS statistic by adding the sign
        # N.B. : since the KS is signed the reference distribution must be the 
        # first term in the function
        KS = F.two_sample_signed_ks_statistic(Ref,compN)
        KSv.append(KS[1])
        
    
    # store KS values of each single cell for feature n
    KS_final[n] = KSv

# convert from dataframe to numpy
KS_final = KS_final.to_numpy()


# Addition of the condition to be related to the the KS matrix. The condition 
# to be related is stored in the dictionary (comp-groups) representing 
# distrition per single cell of Rab spots. It is the last column of the matrix.
# All the values are idetincal, beacause they represent characteristic of the 
# cell. So, you can use the first value.

# This part is avaible only if there is a condition to be related. The 
# avaibility is given by the variable "check = True"


check = False

if check:
    
    new_col = np.zeros((KS_final.shape[0], 1))  # Shape: (rows, 1)
    KS_final = np.hstack((KS_final, new_col))
    
    for i, key in enumerate(comp_groups):
        
        KS_final[i, KS_final.shape[1]-1] = comp_groups[key][0, comp_groups[key].shape[1]-1]
        



""" DATAFRAME CREATION """

# Create new dataframe where the colums contain the name of the feature measured

print("\nDataframe creation")

# Load the column names from the Excel file
# The feature names are listed in an excel file
excel_file = 'features Python2.xlsx'
column_names_df = pd.read_excel(excel_file, sheet_name='Sheet1', header=None)

if check:
    column_names_df['11'] = 'relation'

# Extract the column names from the first row
column_names = column_names_df.iloc[0].tolist()

# Ensure the length of column_names matches the number of columns in your data matrix
# 12
num_columns = KS_final.shape[1]
if len(column_names) != num_columns:
    raise ValueError("Number of column names in Excel file does not match the number of columns in the data matrix")

# Convert the NumPy array to a Pandas DataFrame with the loaded column names
df = pd.DataFrame(KS_final, columns=column_names)


# dataframe saving
#df.to_excel('C:/Users/E14Ge/Desktop/Rab cluster data/single cell analysis/Rab11_COMBO.xlsx',index=False) 


# Record the end time
end_time = time.perf_counter()

# Calculate the elapsed time
elapsed_time = end_time - start_time

# Print the elapsed time
print('\n')
print(f"Execution time: {elapsed_time:.6f} seconds") 
